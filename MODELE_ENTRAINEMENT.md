# ü§ñ Guide d'Entra√Ænement du Mod√®le de Recommandation

## üìã Vue d'ensemble

Ce guide explique comment entra√Æner et sauvegarder le mod√®le de recommandation de livres bas√© sur TF-IDF et similarit√© cosinus.

## üîß Pr√©requis

### 1. Python et D√©pendances
- Python 3.7+ install√©
- D√©pendances Python install√©es (voir `requirements.txt`)

### 2. Base de Donn√©es
- MySQL d√©marr√©
- Base de donn√©es `application_gestion_ai` cr√©√©e
- Table `livres` avec des donn√©es et descriptions

### 3. Structure des Donn√©es
La table `livres` doit contenir au minimum :
- `id_livre` (cl√© primaire)
- `titre` (titre du livre)
- `description` (description/r√©sum√© du livre)
- Autres champs optionnels : `auteur`, `genre`, `image_url`, `stock`, `rating`, `price`

## üöÄ M√©thodes d'Entra√Ænement

### Option 1: Script Automatique (Recommand√©)

#### Sur Windows :
```bash
.\train_model.bat
```

#### Sur Linux/Mac :
```bash
chmod +x train_model.sh
./train_model.sh
```

### Option 2: Commande Manuelle

```bash
# Installer les d√©pendances si n√©cessaire
pip install pandas numpy scikit-learn mysql-connector-python

# Ex√©cuter l'entra√Ænement
python train_and_save_model.py
```

### Option 3: Depuis le Code Python

```python
from recommendation_model import BookRecommendationModel

# Cr√©er l'instance
model = BookRecommendationModel()

# Charger les donn√©es
model.load_books_data()

# Entra√Æner le mod√®le
model.train_model()

# Sauvegarder le mod√®le
model.save_model('book_recommendation_model.pkl')
```

## üìä Processus d'Entra√Ænement

### √âtape 1: Chargement des Donn√©es
```python
# Connexion √† MySQL
connection = mysql.connector.connect(
    host='localhost',
    user='root',
    password='',
    database='application_gestion_ai'
)

# Requ√™te pour r√©cup√©rer les livres
query = """
    SELECT id_livre, titre, description, auteur, genre, 
           image_url, stock, rating, price, created_at, updated_at
    FROM livres 
    WHERE description IS NOT NULL AND description != ''
    ORDER BY id_livre
"""
```

### √âtape 2: Nettoyage des Descriptions
```python
def clean_text(self, text):
    # Supprimer les caract√®res sp√©ciaux
    text = re.sub(r'[^\w\s√†√°√¢√£√§√•√¶√ß√®√©√™√´√¨√≠√Æ√Ø√∞√±√≤√≥√¥√µ√∂√∏√π√∫√ª√º√Ω√æ√ø]', ' ', text)
    
    # Convertir en minuscules
    text = text.lower()
    
    # Supprimer les espaces multiples
    text = re.sub(r'\s+', ' ', text).strip()
    
    return text
```

### √âtape 3: Application TF-IDF
```python
# Configuration du TF-IDF Vectorizer
tfidf_vectorizer = TfidfVectorizer(
    max_features=5000,      # Nombre maximum de features
    stop_words=None,        # Pas de stop words
    ngram_range=(1, 2),     # Unigrammes et bigrammes
    min_df=2,              # Terme dans au moins 2 documents
    max_df=0.95,           # Terme dans max 95% des documents
    lowercase=True,
    strip_accents='unicode'
)

# Application sur les descriptions nettoy√©es
tfidf_matrix = tfidf_vectorizer.fit_transform(descriptions_clean)
```

### √âtape 4: Calcul de la Matrice de Similarit√©
```python
# Calcul de la similarit√© cosinus
similarity_matrix = cosine_similarity(tfidf_matrix)
```

### √âtape 5: Sauvegarde du Mod√®le
```python
model_data = {
    'tfidf_vectorizer': tfidf_vectorizer,
    'similarity_matrix': similarity_matrix,
    'books_data': books_data
}

with open('book_recommendation_model.pkl', 'wb') as f:
    pickle.dump(model_data, f)
```

## üìÅ Fichiers G√©n√©r√©s

### `book_recommendation_model.pkl`
Fichier principal contenant :
- Le TF-IDF Vectorizer entra√Æn√©
- La matrice de similarit√© cosinus
- Les donn√©es des livres (DataFrame pandas)

**Taille typique** : 1-10 MB selon le nombre de livres

## üîç V√©rification du Mod√®le

### Test des Recommandations
```python
# Charger le mod√®le
model = BookRecommendationModel()
model.load_model('book_recommendation_model.pkl')

# Obtenir des recommandations
recommendations = model.get_recommendations(book_id=1, n_recommendations=5)

# Afficher les r√©sultats
for rec in recommendations:
    print(f"- {rec['titre']} (Score: {rec['similarity_score']:.3f})")
```

### Informations du Mod√®le
```python
info = model.get_model_info()
print(f"Livres: {info['books_count']}")
print(f"Features TF-IDF: {info['tfidf_features']}")
print(f"Matrice: {info['similarity_matrix_shape']}")
```

## ‚ö†Ô∏è D√©pannage

### Erreur de Connexion MySQL
```
Erreur de connexion √† la base de donn√©es
```
**Solutions :**
- V√©rifier que MySQL est d√©marr√©
- V√©rifier les param√®tres de connexion dans `recommendation_model.py`
- V√©rifier que la base de donn√©es existe

### Aucun Livre Trouv√©
```
Aucun livre trouv√© dans la base de donn√©es
```
**Solutions :**
- V√©rifier que la table `livres` contient des donn√©es
- V√©rifier que les livres ont des descriptions non vides
- V√©rifier la requ√™te SQL

### Erreur de D√©pendances
```
ModuleNotFoundError: No module named 'pandas'
```
**Solutions :**
```bash
pip install pandas numpy scikit-learn mysql-connector-python
```

### Mod√®le Vide
```
Mod√®le non entra√Æn√©. Entra√Ænez d'abord le mod√®le.
```
**Solutions :**
- Ex√©cuter l'entra√Ænement complet
- V√©rifier que le fichier `.pkl` a √©t√© cr√©√©
- V√©rifier les permissions d'√©criture

## üîÑ Mise √† Jour du Mod√®le

### Quand R√©entra√Æner ?
- Ajout de nouveaux livres
- Modification des descriptions existantes
- Changement significatif du catalogue

### Processus de Mise √† Jour
1. Ajouter/modifier les livres dans la base de donn√©es
2. Ex√©cuter l'entra√Ænement complet
3. Red√©marrer l'API FastAPI si n√©cessaire

## üìà Performance

### Temps d'Entra√Ænement Typiques
- 100 livres : ~5-10 secondes
- 1000 livres : ~30-60 secondes
- 10000 livres : ~2-5 minutes

### Facteurs de Performance
- Nombre de livres
- Longueur des descriptions
- Configuration TF-IDF (max_features, ngram_range)
- Puissance de la machine

## üéØ Optimisations

### Pour de Grands Catalogues
```python
# R√©duire le nombre de features
tfidf_vectorizer = TfidfVectorizer(
    max_features=2000,  # Au lieu de 5000
    min_df=3,          # Au lieu de 2
    max_df=0.90        # Au lieu de 0.95
)
```

### Pour de Petits Catalogues
```python
# Augmenter la sensibilit√©
tfidf_vectorizer = TfidfVectorizer(
    max_features=1000,
    min_df=1,          # Inclure tous les termes
    ngram_range=(1, 3) # Inclure les trigrammes
)
```

## üîê S√©curit√©

### Fichier de Mod√®le
- Le fichier `.pkl` contient des donn√©es sensibles
- Ne pas partager publiquement
- Sauvegarder r√©guli√®rement

### Base de Donn√©es
- Utiliser des identifiants s√©curis√©s
- Limiter les permissions de l'utilisateur MySQL
- Sauvegarder r√©guli√®rement la base de donn√©es

## üìû Support

En cas de probl√®me :
1. V√©rifier les logs d'erreur
2. Consulter ce guide de d√©pannage
3. V√©rifier la configuration de l'environnement
4. Tester avec un petit ensemble de donn√©es
